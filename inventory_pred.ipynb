{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6b5bed9",
   "metadata": {},
   "source": [
    "# WE REMOVED ALL OUTPUTS OF THE FILE BECAUSE THE GITHUB FILE SIZE LIMIT IS: 25 MB AND THE FILE WAS EXCEEDING THAT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4af7796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fabc920",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from chart_studio import plotly\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode,  plot\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import numpy as np\n",
    "import math\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import warnings\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b322eb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'legend.fontsize': 'xx-large',\n",
    "          'figure.figsize': (15, 10),\n",
    "         'axes.labelsize': 'xx-large',\n",
    "         'axes.titlesize':'xx-large',\n",
    "         'xtick.labelsize':'xx-large',\n",
    "         'ytick.labelsize':'xx-large'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e53d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "pylab.rcParams.update(params)\n",
    "DataFrame=pd.read_csv('PLID_Bookings_Problem1_2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16705193",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(DataFrame.head())\n",
    "display(DataFrame.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec217458",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.columns = DataFrame.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c6dcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a000bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame = DataFrame.rename(columns={'business unit':'business_unit', \n",
    "                        'product family':'product_family', \n",
    "                        'plid':'plid', \n",
    "                        'fiscal quarter':'fiscal_quarter', \n",
    "                        'fiscal_month':'fiscal_month', \n",
    "                        'booked_qty':'booked_qty', \n",
    "                        'booking_date':'booking_date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56da74e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.plid.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24689b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.product_family.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fcf0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.business_unit.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb67f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db312189",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(DataFrame.head())\n",
    "display(DataFrame.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796e33cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame[[\"day\", \"month\", \"year\"]] = DataFrame[\"booking_date\"].str.split(\"-\", expand = True)\n",
    "DataFrame.dropna()\n",
    "#CHANGING STRING TO NUMERIC\n",
    "#DataFrame.business_unit = pd.to_numeric(DataFrame['business_unit'], errors='coerce')\n",
    "#business_unit = DataFrame.business_unit.unique() #GIVES 4 UNQUE WH\n",
    "display(DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fae0f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "business_unit = DataFrame.business_unit.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3365df82",
   "metadata": {},
   "outputs": [],
   "source": [
    "plid = DataFrame.plid.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a45a88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc112f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30fc0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.offline as py\n",
    "for i in range(0, len(plid)):\n",
    "    BQ=pd.DataFrame(DataFrame[DataFrame['plid']== plid[i]])\n",
    "    BQ_2013=BQ[BQ['year']==\"2013\"]\n",
    "    print(BQ_2013)\n",
    "    BQ_2013=pd.DataFrame(BQ.groupby('plid', as_index=False)['booked_qty'].mean())\n",
    "    BQ_2013= BQ_2013.sort_values('booked_qty', ascending=False)\n",
    "    BQ_2014=BQ[BQ['year']==\"2014\"]\n",
    "    BQ_2014=pd.DataFrame(BQ.groupby('plid', as_index=False)['booked_qty'].mean())\n",
    "    BQ_2014= BQ_2014.sort_values('booked_qty', ascending=False)\n",
    "    BQ_2015=BQ[BQ['year']==\"2015\"]\n",
    "    BQ_2015=pd.DataFrame(BQ.groupby('plid', as_index=False)['booked_qty'].mean())\n",
    "    BQ_2015= BQ_2015.sort_values('booked_qty', ascending=False)\n",
    "    BQ_2016=BQ[BQ['year']==\"2016\"]\n",
    "    BQ_2016=pd.DataFrame(BQ.groupby('plid', as_index=False)['booked_qty'].mean())\n",
    "    BQ_2016= BQ_2016.sort_values('booked_qty', ascending=False)\n",
    "    BQ_2017=BQ[BQ['year']==\"2017\"]\n",
    "    BQ_2017=pd.DataFrame(BQ.groupby('plid', as_index=False)['booked_qty'].mean())\n",
    "    BQ_2017= BQ_2017.sort_values('booked_qty', ascending=False)\n",
    "    BQ_2018=BQ[BQ['year']==\"2018\"]\n",
    "    BQ_2018=pd.DataFrame(BQ.groupby('plid', as_index=False)['booked_qty'].mean())\n",
    "    BQ_2018= BQ_2018.sort_values('booked_qty', ascending=False)\n",
    "    BQ_2019=BQ[BQ['year']==\"2019\"]\n",
    "    BQ_2019=pd.DataFrame(BQ.groupby('plid', as_index=False)['booked_qty'].mean())\n",
    "    BQ_2019= BQ_2019.sort_values('booked_qty', ascending=False)\n",
    "    BQ_2020=BQ[BQ['year']==\"2020\"]\n",
    "    BQ_2020=pd.DataFrame(BQ.groupby('plid', as_index=False)['booked_qty'].mean())\n",
    "    BQ_2020= BQ_2020.sort_values('booked_qty', ascending=False)\n",
    "    BQ_2021=BQ[BQ['year']==\"2021\"]\n",
    "    BQ_2021=pd.DataFrame(BQ.groupby('plid', as_index=False)['booked_qty'].mean())\n",
    "    BQ_2021= BQ_2021.sort_values('booked_qty', ascending=False)\n",
    "    BQ_2022=BQ[BQ['year']==\"2022\"]\n",
    "    BQ_2022=pd.DataFrame(BQ.groupby('plid', as_index=False)['booked_qty'].mean())\n",
    "    BQ_2022= BQ_2022.sort_values('booked_qty', ascending=False)\n",
    "    trace1 = go.Bar(x=BQ_2013['plid'],  y=BQ_2013['booked_qty'], name='Year_2013')\n",
    "    trace2 = go.Bar(x=BQ_2014['plid'],  y=BQ_2014['booked_qty'], name='Year_2014')\n",
    "    trace3 = go.Bar(x=BQ_2015['plid'],  y=BQ_2015['booked_qty'], name='Year_2015')\n",
    "    trace4 = go.Bar(x=BQ_2016['plid'],  y=BQ_2016['booked_qty'], name='Year_2016')\n",
    "    trace5 = go.Bar(x=BQ_2017['plid'],  y=BQ_2017['booked_qty'], name='Year_2017')\n",
    "    trace6 = go.Bar(x=BQ_2018['plid'],  y=BQ_2018['booked_qty'], name='Year_2018')\n",
    "    trace7 = go.Bar(x=BQ_2019['plid'],  y=BQ_2019['booked_qty'], name='Year_2019')\n",
    "    trace8 = go.Bar(x=BQ_2020['plid'],  y=BQ_2020['booked_qty'], name='Year_2020')\n",
    "    trace9 = go.Bar(x=BQ_2021['plid'],  y=BQ_2021['booked_qty'], name='Year_2021')\n",
    "    trace10 = go.Bar(x=BQ_2022['plid'],  y=BQ_2022['booked_qty'], name='Year_2022')\n",
    "    fig = tools.make_subplots(rows=2, cols=10)\n",
    "    fig.append_trace(trace10, 1, 1)\n",
    "    fig.append_trace(trace9, 1, 2)\n",
    "    fig.append_trace(trace8, 1, 3)\n",
    "    fig.append_trace(trace7, 1, 4)\n",
    "    fig.append_trace(trace6, 1, 5)\n",
    "    fig.append_trace(trace5, 1, 6)\n",
    "    fig.append_trace(trace4, 1, 7)\n",
    "    fig.append_trace(trace3, 1, 8)\n",
    "    fig.append_trace(trace2, 1, 9)\n",
    "    fig.append_trace(trace1, 1, 10)\n",
    "    layout=fig['layout'].update(height=500, width=1200, title='booked_qty vs product_family with respect to all years for '+ str (business_unit[i]),xaxis=dict(\n",
    "        title='plid',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='booked_qty',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f')))\n",
    "    py.iplot(fig, filename='stacked-subplots')#, layout=layout)\n",
    "    plot(fig, filename='stacked-subplots')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1b6424",
   "metadata": {},
   "source": [
    "# Function to separate warehouse according to year and concatenate it vertically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d19faab",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame['plid'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a1d42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(DataFrame.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c080226",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame[\"Pandas_Datestamp\"] = pd.to_datetime(DataFrame[\"year\"] + \"-\" + DataFrame[\"month\"] + \"-\" + DataFrame[\"day\"])\n",
    "DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c76c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION FOR DIFFERENT WAREHOUSES\n",
    "def diff_business_unit(CSWBU_A):\n",
    "  \n",
    "    #SCALING THE ORDER DEMAND\n",
    "    \n",
    "    CSWBU=pd.DataFrame(DataFrame[DataFrame['plid']== CSWBU_A]) #EXTRACTING A SPECIFIC WAREHOUSE\n",
    "    cols_to_norm = ['booked_qty'] #SCALING\n",
    "    CSWBU[cols_to_norm] = CSWBU[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min())) #SCALING\n",
    "    CSWBU.sort_values(by='Pandas_Datestamp')\n",
    "    #print(CSWBU)\n",
    "    \n",
    "    #SEPARATING AS PER YEAR\n",
    "    CSWBU_2013=CSWBU[CSWBU['year']==\"2013\"]\n",
    "    #print(CSWBU_2013)\n",
    "    CSWBU_2013['month'] = CSWBU_2013['Pandas_Datestamp'].apply(lambda x: x.strftime('%Y-%m-01')) #FIRST DAY OF EVERY MONTH \n",
    "    CSWBU_2013=pd.DataFrame(CSWBU_2013.groupby('month', as_index=False)['booked_qty'].mean())\n",
    "    CSWBU_2013.sort_values(by='month')\n",
    "\n",
    "    CSWBU_2014=CSWBU[CSWBU['year']==\"2014\"]\n",
    "    CSWBU_2014['month'] = CSWBU_2014['Pandas_Datestamp'].apply(lambda x: x.strftime('%Y-%m-01')) #FIRST DAY OF EVERY MONTH\n",
    "    CSWBU_2014=pd.DataFrame(CSWBU_2014.groupby('month', as_index=False)['booked_qty'].mean())\n",
    "    CSWBU_2014.sort_values(by='month')\n",
    "\n",
    "    CSWBU_2015=CSWBU[CSWBU['year']==\"2015\"]\n",
    "    CSWBU_2015['month'] = CSWBU_2015['Pandas_Datestamp'].apply(lambda x: x.strftime('%Y-%m-01')) #FIRST DAY OF EVERY MONTH\n",
    "    CSWBU_2015=pd.DataFrame(CSWBU_2015.groupby('month', as_index=False)['booked_qty'].mean())\n",
    "    CSWBU_2015.sort_values(by='month')\n",
    "\n",
    "    CSWBU_2016=CSWBU[CSWBU['year']==\"2016\"]\n",
    "    CSWBU_2016['month'] = CSWBU_2016['Pandas_Datestamp'].apply(lambda x: x.strftime('%Y-%m-01'))#FIRST DAY OF EVERY MONTH\n",
    "    CSWBU_2016=pd.DataFrame(CSWBU_2016.groupby('month', as_index=False)['booked_qty'].mean())\n",
    "    CSWBU_2016.sort_values(by='month')\n",
    "\n",
    "    CSWBU_2017=CSWBU[CSWBU['year']==\"2017\"]\n",
    "    CSWBU_2017['month'] = CSWBU_2017['Pandas_Datestamp'].apply(lambda x: x.strftime('%Y-%m-01')) #FIRST DAY OF EVERY MONTH\n",
    "    CSWBU_2017=pd.DataFrame(CSWBU_2017.groupby('month', as_index=False)['booked_qty'].mean())\n",
    "    CSWBU_2017.sort_values(by='month')\n",
    "    \n",
    "    CSWBU_2018=CSWBU[CSWBU['year']==\"2018\"]\n",
    "    CSWBU_2018['month'] = CSWBU_2018['Pandas_Datestamp'].apply(lambda x: x.strftime('%Y-%m-01')) #FIRST DAY OF EVERY MONTH\n",
    "    CSWBU_2018=pd.DataFrame(CSWBU_2018.groupby('month', as_index=False)['booked_qty'].mean())\n",
    "    CSWBU_2018.sort_values(by='month')\n",
    "    \n",
    "    CSWBU_2019=CSWBU[CSWBU['year']==\"2019\"]\n",
    "    CSWBU_2019['month'] = CSWBU_2019['Pandas_Datestamp'].apply(lambda x: x.strftime('%Y-%m-01')) #FIRST DAY OF EVERY MONTH\n",
    "    CSWBU_2019=pd.DataFrame(CSWBU_2019.groupby('month', as_index=False)['booked_qty'].mean())\n",
    "    CSWBU_2019.sort_values(by='month')\n",
    "    \n",
    "    CSWBU_2020=CSWBU[CSWBU['year']==\"2020\"]\n",
    "    CSWBU_2020['month'] = CSWBU_2020['Pandas_Datestamp'].apply(lambda x: x.strftime('%Y-%m-01')) #FIRST DAY OF EVERY MONTH\n",
    "    CSWBU_2020=pd.DataFrame(CSWBU_2020.groupby('month', as_index=False)['booked_qty'].mean())\n",
    "    CSWBU_2020.sort_values(by='month')\n",
    "    \n",
    "    CSWBU_2021=CSWBU[CSWBU['year']==\"2021\"]\n",
    "    CSWBU_2021['month'] = CSWBU_2021['Pandas_Datestamp'].apply(lambda x: x.strftime('%Y-%m-01')) #FIRST DAY OF EVERY MONTH\n",
    "    CSWBU_2021=pd.DataFrame(CSWBU_2021.groupby('month', as_index=False)['booked_qty'].mean())\n",
    "    CSWBU_2021.sort_values(by='month')\n",
    "    \n",
    "    CSWBU_2022=CSWBU[CSWBU['year']==\"2022\"]\n",
    "    CSWBU_2022['month'] = CSWBU_2022['Pandas_Datestamp'].apply(lambda x: x.strftime('%Y-%m-01')) #FIRST DAY OF EVERY MONTH\n",
    "    CSWBU_2022=pd.DataFrame(CSWBU_2022.groupby('month', as_index=False)['booked_qty'].mean())\n",
    "    CSWBU_2022.sort_values(by='month')\n",
    "#CONCATENATION\n",
    "\n",
    "    CSWBU_ALLYEARS = pd.concat([CSWBU_2013,CSWBU_2014,CSWBU_2015,CSWBU_2016,CSWBU_2017,CSWBU_2018,CSWBU_2019,CSWBU_2020,CSWBU_2021,CSWBU_2022]).reset_index(drop=True) #, axis=1\n",
    "    CSWBU_ALLYEARS.index = CSWBU_ALLYEARS['month']\n",
    "    CSWBU_ALLYEARS.drop(columns='month')\n",
    "    CSWBU_ALLYEARS= CSWBU_ALLYEARS.drop(columns='month')\n",
    "    CSWBU_ALLYEARS.reset_index(inplace=True)\n",
    "    CSWBU_ALLYEARS['month'] = pd.to_datetime(CSWBU_ALLYEARS['month'])\n",
    "    CSWBU_ALLYEARS = CSWBU_ALLYEARS.set_index('month')\n",
    "    #ROLLING AVERGAGE FORMULA - TRIAL WITH MOVING WINDOW\n",
    "    CSWBU_ALLYEARS['MA_3']= CSWBU_ALLYEARS.booked_qty.rolling(3).mean()\n",
    "    CSWBU_ALLYEARS['MA_3_std']= CSWBU_ALLYEARS.booked_qty.rolling(3).std() #QUATERLY\n",
    "    CSWBU_ALLYEARS['plid'] = CSWBU_A\n",
    "    #print(CSWBU_ALLYEARS['MA_3'])\n",
    "    \n",
    "    return CSWBU_ALLYEARS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44e9a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "        BOLD = '\\033[1m'\n",
    "        UNDERLINE = '\\033[4m'\n",
    "        END = '\\033[0m'\n",
    "for i in range(0,len(business_unit)):\n",
    "    print('\\n\\n\\n\\n___________________________________________________________________________________________________________________________')\n",
    "    print(color.BOLD  + '\\n\\t\\t\\t %s \\n'% plid[i] + color.END)\n",
    "    print(diff_business_unit(plid[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91ca0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(diff_business_unit(plid[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7422d34f",
   "metadata": {},
   "source": [
    "# Function to test the stationarity of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26dbf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "import pandas as pd\n",
    "\n",
    "def test_stationarity(plid,timeseries):\n",
    "    \n",
    "    #Determing rolling statistics\n",
    "    rolmean =  timeseries.rolling(12).mean()\n",
    "    rolstd = timeseries.rolling(window=12).std()\n",
    "\n",
    "    #Plot rolling statistics:\n",
    "    orig = plt.plot(timeseries, color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    #Perform Dickey-Fuller test:\n",
    "    print('Results of Dickey-Fuller Test for %s:' % plid)\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    p_value = dftest[1]\n",
    "    print('p-value: %.4f' % p_value)\n",
    "\n",
    "    # Create a new dataframe to store the p-value for the current plid\n",
    "    df = pd.DataFrame(data={'plid': [plid], 'p_value': [p_value]})\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Create an empty dataframe to store the p-values for all plid\n",
    "df_all_plid = pd.DataFrame(columns=['plid', 'p_value'])\n",
    "\n",
    "# Loop through all the plid\n",
    "for i in range(0,len(plid)):\n",
    "    current_plid = plid[i]\n",
    "    current_timeseries = diff_business_unit(current_plid).booked_qty\n",
    "    \n",
    "    # Test stationarity and obtain the p-value for the current plid\n",
    "    df_plid = test_stationarity(current_plid, current_timeseries)\n",
    "    \n",
    "    # Append the dataframe for the current plid to the df_all_plid\n",
    "    df_all_plid = pd.concat([df_all_plid, df_plid], ignore_index=True)\n",
    "\n",
    "# Create a separate dataframe for plids with a p-value greater than 0.05\n",
    "df_high_pvalue_plid = df_all_plid[df_all_plid['p_value'] > 0.05]\n",
    "df_low_pvalue_plid = df_all_plid[df_all_plid['p_value'] < 0.05]\n",
    "print('\\n\\n\\n\\n___________________________________________________________________________________________________________________________')\n",
    "print(color.BOLD  + '\\n\\n\\t\\t\\t\\t\\t\\t\\t Summary of p-values \\n' + color.END)\n",
    "print(df_all_plid)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41369e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n\\n\\n\\n___________________________________________________________________________________________________________________________')\n",
    "print(color.BOLD  + '\\n\\n\\t\\t\\t\\t\\t\\t\\t High p-value plids \\n' + color.END)\n",
    "print(df_high_pvalue_plid)\n",
    "\n",
    "print('\\n\\n\\n\\n___________________________________________________________________________________________________________________________')\n",
    "print(color.BOLD  + '\\n\\n\\t\\t\\t\\t\\t\\t\\t low p-value plids \\n' + color.END)\n",
    "print(df_low_pvalue_plid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae48193",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame[DataFrame['plid'] == \"DN2-CPU-I8276\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a50bf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame[\"Pandas_Datestamp\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f8c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pmdarima.arima import auto_arima\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['plid', 'p', 'd', 'q'])\n",
    "\n",
    "# Create an empty DataFrame to store the predictions\n",
    "predictions_df = pd.DataFrame(columns=['plid', 'predicted_values'])\n",
    "\n",
    "for i in range(0, 250):\n",
    "    # Split data into training and testing sets\n",
    "    data = diff_business_unit(plid[i])\n",
    "    train = data.iloc[0:int(len(data)*0.7)]\n",
    "    test = data.iloc[int(len(data)*0.7)+1:]\n",
    "    \n",
    "    # Fit auto_arima model on training data\n",
    "    stepwise_model = auto_arima(train.booked_qty, start_p=1, start_q=1,max_p=3, max_q=3, m=25,\n",
    "                                start_P=0, seasonal=True, d=1, D=0, trace=True,\n",
    "                                error_action='ignore', suppress_warnings=True, stepwise=True,)\n",
    "    \n",
    "    order_in = stepwise_model.order\n",
    "    seasonal_order_in = stepwise_model.seasonal_order\n",
    "    plid_val = plid[i]\n",
    "    \n",
    "    # Store the results in the DataFrame\n",
    "    results_df.loc[i] = [plid_val, order_in[0], order_in[1], order_in[2]]\n",
    "    \n",
    "    print('\\n\\n\\n\\n___________________________________________________________________________________________________________________________')\n",
    "    print(color.BOLD  + '\\n\\n\\t\\t\\t\\t\\t\\t\\t %s \\n'% plid[i] + color.END)\n",
    "    print('Least AIC ', stepwise_model.aic())\n",
    "    print('Least BIC ', stepwise_model.bic())\n",
    "    print(stepwise_model.summary())\n",
    "    \n",
    "    # Make SARIMAX prediction on testing data\n",
    "    mod = sm.tsa.statespace.SARIMAX(train.booked_qty, trend='n', order=order_in , seasonal_order=seasonal_order_in,enforce_invertibility=False)\n",
    "    results = mod.fit()\n",
    "    prediction_1 = results.forecast(steps=len(test))\n",
    "    print('Predictions:')\n",
    "    print(prediction_1)\n",
    "    #prediction_1_ci = prediction_1.conf_int()\n",
    "    ##pred = prediction_1.predicted_mean\n",
    "    #print()\n",
    "    # Store the predictions in the DataFrame\n",
    "    predictions_df.loc[i] = [plid_val, pred.values]\n",
    "    #print(\"jfhbrejbfh\")\n",
    "    \n",
    "    #\n",
    "    #print(\"jfhbrejbfh\")\n",
    "    \n",
    "\n",
    "# Print the results\n",
    "print(results_df.head())\n",
    "print(predictions_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1a3e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ab3316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "model = sm.tsa.ARIMA(DataFrame[plid[]\"CBR-D121-DS-MOD\"], order=(1,1,2))\n",
    "results = model.fit()\n",
    "\n",
    "# Generate predictions from one date to another\n",
    "start_date = '2023-01-01'\n",
    "end_date = '2023-3-1'\n",
    "pred = results.predict(start=start_date, end=end_date, dynamic=True)\n",
    "\n",
    "# Plot the results\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "data.plot(ax=ax)\n",
    "pred.plot(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c040b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pmdarima.arima import auto_arima\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode,  plot\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['plid', 'p', 'd', 'q'])\n",
    "\n",
    "# Create an empty DataFrame to store the predictions\n",
    "predictions_df = pd.DataFrame(columns=['plid', 'predicted_values'])\n",
    "\n",
    "for i in range(0,5):\n",
    "    train = diff_business_unit(plid[i]).iloc[0:int(len(diff_business_unit(plid[i]))*0.7)]\n",
    "    test = diff_business_unit(plid[i]).iloc[int(len(diff_business_unit(plid[i]))*0.7)+1:]\n",
    "    print('\\n\\n\\n\\n___________________________________________________________________________________________________________________________')\n",
    "    print(color.BOLD  + '\\n\\n\\t\\t\\t\\t\\t\\t\\t %s \\n'% plid[i] + color.END)\n",
    "    stepwise_model = auto_arima(train.booked_qty, start_p=1, start_q=1,max_p=3, max_q=3, m=25,\n",
    "                           start_P=0, seasonal=True,\n",
    "                           d=1, D=0, trace=True,\n",
    "                           error_action='ignore',  \n",
    "                           suppress_warnings=True, \n",
    "                           stepwise=True,)\n",
    "    order_in = stepwise_model.order\n",
    "    seasonal_order_in = stepwise_model.seasonal_order\n",
    "    plid_val = plid[i]\n",
    "    \n",
    "    # Store the results in the DataFrame\n",
    "    results_df.loc[i] = [plid_val, order_in[0], order_in[1], order_in[2]]\n",
    "    \n",
    "    print('Least AIC ',stepwise_model.aic())\n",
    "    print('Least BIC ',stepwise_model.bic())\n",
    "    \n",
    "    mod = sm.tsa.statespace.SARIMAX(train.booked_qty, trend='n', order=order_in , seasonal_order=seasonal_order_in,enforce_invertibility=False)\n",
    "    results = mod.fit()\n",
    "    print('\\n\\n\\n',results.summary())\n",
    "    \n",
    "    print('\\n\\n\\n\\t\\t\\t\\t\\t\\t Plotting Diagnostics')\n",
    "    results.plot_diagnostics(figsize=(20, 14))\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\n\\n\\n\\t\\t\\t\\t\\t\\t Forecasting using trained model - 70% Data ')\n",
    "    \n",
    "    prediction_1 = results.get_forecast(steps=len(test))\n",
    "    prediction_1_ci = prediction_1.conf_int()\n",
    "    pred = prediction_1.predicted_mean\n",
    "    \n",
    "    # Store the predictions in the DataFrame\n",
    "    #predictions_df.loc[i] = [plid_val, pred.values]\n",
    "    predictions_df = predictions_df.append({'plid': plid_val, 'predicted_values': pred.values}, ignore_index=True)\n",
    "    \n",
    "    print('Predictions:')\n",
    "    print('Predictions:')\n",
    "    print(pred)\n",
    "    \n",
    "    \n",
    "    #prediction_1 = results.get_forecast(start = \"2023-01-01\", end = \"2023-03-01\", dynamic = True, full_results = True)\n",
    "    #prediction_1 = results.get_forecast()\n",
    "\n",
    "    #get_prediction(start = 50, end = 152, dynamic = True, full_results = True, exog = exog_test)\n",
    "    #prediction_1_ci = prediction_1.conf_int()\n",
    "    #print(prediction_1.predicted_mean['2016-01':'2017-10'])\n",
    "    \n",
    "    #pred = prediction_1.predicted_mean['2016-01':'2017-10']\n",
    "    #print(prediction_1_ci.summary_frame())\n",
    "    \n",
    "    #print(prediction_1.predicted_mean['2023-01':'2023-10'])\n",
    "    \n",
    "    #pred = prediction_1.predicted_mean['2023-01':'2023-10']\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Print the dataframe of forecasting\n",
    "    print('\\n\\n\\n\\t\\t\\t\\t\\t\\t Dataframe of Forecasting ')\n",
    "    Prediction_df = pd.DataFrame(pred,columns=['ORDER_DEMAND_FORECAST'])\n",
    "    print(Prediction_df)\n",
    "    \n",
    "    #print(\"%s\",% Warehouse[i].center())\n",
    "    \n",
    "    #Prediction_df = pd.DataFrame(prediction_1,columns=['ORDER_DEMAND_FORECAST'])\n",
    "    #Prediction_df\n",
    "\n",
    "    Given = go.Scatter(x=diff_business_unit(business_unit[i]).index, y=diff_business_unit(business_unit[i]).booked_qty, mode = 'lines+markers',name = 'Order_Demand'+ business_unit[i])\n",
    "    Predicted=go.Scatter(x=Prediction_df.index, y=Prediction_df.ORDER_DEMAND_FORECAST, mode = 'lines+markers',name = 'Predicted_Order_Demand'+ business_unit[i])\n",
    "    #Actual = go.Scatter(x=WH_A_ALLYEARS_FO.index, y=WH_A_ALLYEARS_FO.Order_Demand, mode = 'lines+markers',name = 'Actual')\n",
    "    Final_Visu =[Given,Predicted]\n",
    "    layout = go.Layout(\n",
    "    title='Forecasted Order Demand for ' + business_unit[i],\n",
    "    xaxis=dict(\n",
    "        title='Years',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Order Demand',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "    Visu = go.Figure(data=Final_Visu, layout=layout)\n",
    "    print(plot(Visu, filename='styling-names'))\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323dadf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['plid', 'p', 'd', 'q'])\n",
    "\n",
    "for i in range(0, 250):\n",
    "    train = diff_business_unit(plid[i]).iloc[0:int(len(diff_business_unit(plid[i]))*0.7)]\n",
    "    test = diff_business_unit(plid[i]).iloc[int(len(diff_business_unit(plid[i]))*0.7)+1:]\n",
    "    stepwise_model = auto_arima(train.booked_qty, start_p=1, start_q=1,max_p=3, max_q=3, m=25,\n",
    "                                start_P=0, seasonal=True, d=1, D=0, trace=True,\n",
    "                                error_action='ignore', suppress_warnings=True, stepwise=True,)\n",
    "    \n",
    "    order_in = stepwise_model.order\n",
    "    plid_val = plid[i]\n",
    "    \n",
    "    # Store the results in the DataFrame\n",
    "    results_df.loc[i] = [plid_val, order_in[0], order_in[1], order_in[2]]\n",
    "    \n",
    "    print('\\n\\n\\n\\n___________________________________________________________________________________________________________________________')\n",
    "    print(color.BOLD  + '\\n\\n\\t\\t\\t\\t\\t\\t\\t %s \\n'% plid[i] + color.END)\n",
    "    print('Least AIC ', stepwise_model.aic())\n",
    "    print('Least BIC ', stepwise_model.bic())\n",
    "    print(stepwise_model.summary())\n",
    "\n",
    "# Print the results\n",
    "print(results_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427fc740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "results_df = pd.DataFrame(columns=['plid', 'quarter', 'p', 'd', 'q', 'predicted_values'])\n",
    "\n",
    "for i in range(0, 250):\n",
    "    # Split data into quarters\n",
    "    data = diff_business_unit(plid[i])\n",
    "    quarters = [data.iloc[(k*len(data)//4):((k+1)*len(data)//4)] for k in range(4)]\n",
    "    \n",
    "    for j in range(4):\n",
    "        train = pd.concat(quarters[:j] + quarters[j+1:])\n",
    "        test = quarters[j]\n",
    "        \n",
    "        stepwise_model = auto_arima(train.booked_qty, start_p=1, start_q=1, max_p=3, max_q=3, m=25,\n",
    "                                    start_P=0, seasonal=True, d=1, D=0, trace=True,\n",
    "                                    error_action='ignore', suppress_warnings=True, stepwise=True)\n",
    "\n",
    "        order_in = stepwise_model.order\n",
    "        plid_val = plid[i]\n",
    "        quarter_val = j + 1\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        predicted_values = stepwise_model.predict(n_periods=len(test))\n",
    "\n",
    "        # Store the results in the DataFrame\n",
    "        results_df = results_df.append({'plid': plid_val, 'quarter': quarter_val,\n",
    "                                        'p': order_in[0], 'd': order_in[1], 'q': order_in[2],\n",
    "                                        'predicted_values': predicted_values}, ignore_index=True)\n",
    "        \n",
    "        print('\\n\\n\\n\\n___________________________________________________________________________________________________________________________')\n",
    "        print(color.BOLD  + '\\n\\n\\t\\t\\t\\t\\t\\t\\t PLID: %s  Quarter: %d \\n'% (plid[i], quarter_val) + color.END)\n",
    "        print('Least AIC ', stepwise_model.aic())\n",
    "        print('Least BIC ', stepwise_model.bic())\n",
    "        print(stepwise_model.summary())\n",
    "        \n",
    "# Print the results\n",
    "print(results_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2d99d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyramid.arima import auto_arima\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode,  plot\n",
    "\n",
    "for i in range(0,len(business_unit)):\n",
    "    train = diff_business_unit(business_unit[i]).iloc[0:int(len(diff_business_unit(business_unit[i]))*0.7)]\n",
    "    test = diff_business_unit(business_unit[i]).iloc[int(len(diff_business_unit(business_unit[i]))*0.7)+1:]\n",
    "    print  '\\n\\n\\n\\n___________________________________________________________________________________________________________________________'\n",
    "    print color.BOLD  + '\\n\\n\\t\\t\\t\\t\\t\\t\\t %s \\n'% business_unit[i] + color.END\n",
    "    stepwise_model = auto_arima(train.booked_qty, start_p=1, start_q=1,max_p=3, max_q=3, m=25,\n",
    "                           start_P=0, seasonal=True,\n",
    "                           d=1, D=1, trace=True,\n",
    "                           error_action='ignore',  \n",
    "                           suppress_warnings=True, \n",
    "                           stepwise=True,)\n",
    "    order_in = stepwise_model.order\n",
    "    seasonal_order_in = stepwise_model.seasonal_order\n",
    "    print'Least AIC ',stepwise_model.aic()\n",
    "    print'Least BIC ',stepwise_model.bic()\n",
    "   \n",
    "    mod = sm.tsa.statespace.SARIMAX(train.booked_qty, trend='n', order=order_in , seasonal_order=seasonal_order_in,enforce_invertibility=False)\n",
    "    results = mod.fit()\n",
    "    print '\\n\\n\\n',results.summary()\n",
    "    \n",
    "    print '\\n\\n\\n\\t\\t\\t\\t\\t\\t Plotting Diagnostics'\n",
    "    results.plot_diagnostics(figsize=(20, 14))\n",
    "    plt.show()\n",
    "    \n",
    "    print '\\n\\n\\n\\t\\t\\t\\t\\t\\t Forecasting using trained model - 70% Data '\n",
    "    prediction_1 = results.get_forecast('2017-12')\n",
    "    prediction_1_ci = prediction_1.conf_int()\n",
    "    print(prediction_1.predicted_mean['2016-01':'2017-10'])\n",
    "    \n",
    "    pred = prediction_1.predicted_mean['2016-01':'2017-10']\n",
    "    \n",
    "    print '\\n\\n\\n\\t\\t\\t\\t\\t\\t Dataframe of Forecasting '\n",
    "    Prediction_df = pd.DataFrame(pred,columns=['ORDER_DEMAND_FORECAST'])\n",
    "    print Prediction_df\n",
    "    \n",
    "    #print(\"%s\",% Warehouse[i].center())\n",
    "    \n",
    "   # Prediction_df = pd.DataFrame(prediction_1,columns=['ORDER_DEMAND_FORECAST'])\n",
    "   # Prediction_df\n",
    "\n",
    "    Given = go.Scatter(x=diff_business_unit(business_unit[i]).index, y=diff_business_unitwarehouse(business_unit[i]).booked_qty, mode = 'lines+markers',name = 'Order_Demand'+ business_unit[i])\n",
    "    Predicted=go.Scatter(x=Prediction_df.index, y=Prediction_df.ORDER_DEMAND_FORECAST, mode = 'lines+markers',name = 'Predicted_Order_Demand'+ business_unit[i])\n",
    "    #Actual = go.Scatter(x=WH_A_ALLYEARS_FO.index, y=WH_A_ALLYEARS_FO.Order_Demand, mode = 'lines+markers',name = 'Actual')\n",
    "    Final_Visu =[Given,Predicted]\n",
    "    layout = go.Layout(\n",
    "    title='Forecasted Order Demand for ' + business_unit[i],\n",
    "    xaxis=dict(\n",
    "        title='Years',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Order Demand',\n",
    "        titlefont=dict(\n",
    "            family='Courier New, monospace',\n",
    "            size=18,\n",
    "            color='#7f7f7f'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "    Visu = go.Figure(data=Final_Visu, layout=layout)\n",
    "    print plot(Visu, filename='styling-names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcef992",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97696a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales distribution across the train data\n",
    "train_df, test_df = DataFrame[0:int(len(DataFrame)*0.9)], DataFrame[int(len(DataFrame)*0.9):]\n",
    "#train_data, test_data = temp['Booked_Qty']\n",
    "#train = diff_business_unit(business_unit[i]).iloc[0:int(len(diff_business_unit(business_unit[i]))*0.7)]\n",
    "#test = diff_business_unit(business_unit[i]).iloc[int(len(diff_business_unit(business_unit[i]))*0.7)+1:]\n",
    "def sales_dist(data):\n",
    "    \"\"\"\n",
    "        Sales_dist used for Checing Sales Distribution.\n",
    "        data :  contain data frame which contain sales data\n",
    "    \"\"\"\n",
    "    sales_df = DataFrame.copy(deep=True)\n",
    "    sales_df['sales_bins'] = pd.cut(sales_df.booked_qty, [0, 50, 100, 150, 200, 250])\n",
    "    print('Max sale:', sales_df.booked_qty.max())\n",
    "    print('Min sale:', sales_df.booked_qty.min())\n",
    "    print('Avg sale:', sales_df.booked_qty.mean())\n",
    "    print()\n",
    "    return sales_df\n",
    "\n",
    "sales_df = sales_dist(train_df)\n",
    "\n",
    "# Total number of data points\n",
    "total_points = pd.value_counts(sales_df.sales_bins).sum()\n",
    "print('Sales bucket v/s Total percentage:')\n",
    "display(pd.value_counts(sales_df.sales_bins).apply(lambda s: (s/total_points)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7d8b84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
